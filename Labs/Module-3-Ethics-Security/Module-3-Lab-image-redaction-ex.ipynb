{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 3.2 Image Redaction - Exercise\n",
    "Now let's practice what you have learned. \n",
    "\n",
    "We are going to a variation. Rather than redact the face, let's redact the areas within the eyes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact an image - CPU\n",
    "Now lets blur the are within the rectangle to redact the face using the OpenCV GaussianBlur function. We will not identify eyes in this code block, just the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5ca73cd08d4721b9cdc8c503021fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 16 ms, total: 220 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image using OpenCV\n",
    "image = cv2.imread('lena_color.tif')\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "# Converting BGR image into a RGB image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fpath='./cascades/haarcascade_frontalface_alt.xml'\n",
    "epath='./cascades/haarcascade_eye.xml'\n",
    "face_detect = cv2.CascadeClassifier(fpath)\n",
    "eye_detect = cv2.CascadeClassifier(epath)\n",
    "\n",
    "faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    \n",
    "    eyes = eye_detect.detectMultiScale(roi_gray)\n",
    "    #fix me -- add in code block to redact the eyes\n",
    "    \n",
    "  \n",
    "# Display the output\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "image_widget.value = bytes(cv2.imencode('.jpg', image)[1])\n",
    "display(image_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact an image -GPU\n",
    "Now lets use the GPU to run the classifier. \n",
    "Copy the code from above into this next code block and modify to use the GPU to identify the face and eyes and redact just the eyes. For this exercise, just enable the CUDA classifier for the face detection, not the eye detection.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a gpu version of the code block above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
